 multi_agent_debate/
│
├── main.py
├── agents/
│   ├── agent_base.py
│   ├── claim_extractor.py
│   ├── fact_checker.py
│   ├── contradiction_detector.py
│   └── moderator.py
│
├── debate_manager.py
└── utils.py

# agents/agent_base.py

class Agent:
    def __init__(self, name):
        self.name = name

    def respond(self, input_text):
        raise NotImplementedError("Each agent must implement respond()")

        # agents/claim_extractor.py

from agents.agent_base import Agent

class ClaimExtractor(Agent):
    def __init__(self):
        super().__init__("Claim Extractor")

    def respond(self, text):
        sentences = text.split(".")
        claims = [s.strip() for s in sentences if len(s.strip()) > 10]
        return claims

# agents/fact_checker.py

from agents.agent_base import Agent

class FactChecker(Agent):
    def __init__(self):
        super().__init__("Fact Checker")

    def respond(self, claims):
        verified = []
        for claim in claims:
            if "always" in claim.lower() or "never" in claim.lower():
                verified.append((claim, "Suspicious"))
            else:
                verified.append((claim, "Likely True"))
        return verified




# agents/contradiction_detector.py

from agents.agent_base import Agent

class ContradictionDetector(Agent):
    def __init__(self):
        super().__init__("Contradiction Detector")

    def respond(self, claims):
        contradictions = []
        for i in range(len(claims)):
            for j in range(i + 1, len(claims)):
                if "not" in claims[i].lower() and claims[j].lower() in claims[i].lower():
                    contradictions.append((claims[i], claims[j]))
        return contradictions





# agents/moderator.py

from agents.agent_base import Agent

class Moderator(Agent):
    def __init__(self):
        super().__init__("Moderator")

    def respond(self, claims, facts, contradictions):
        report = {
            "total_claims": len(claims),
            "verified_claims": facts,
            "contradictions_found": contradictions,
            "consistency_score": max(0, 100 - (len(contradictions) * 20))
        }
        return report


        # debate_manager.py

from agents.claim_extractor import ClaimExtractor
from agents.fact_checker import FactChecker
from agents.contradiction_detector import ContradictionDetector
from agents.moderator import Moderator

class DebateManager:
    def __init__(self):
        self.extractor = ClaimExtractor()
        self.checker = FactChecker()
        self.detector = ContradictionDetector()
        self.moderator = Moderator()

    def run(self, text):
        claims = self.extractor.respond(text)
        facts = self.checker.respond(claims)
        contradictions = self.detector.respond(claims)
        final_report = self.moderator.respond(claims, facts, contradictions)
        return final_report

        # main.py

from debate_manager import DebateManager

if __name__ == "__main__":
    text = """
    The Earth revolves around the Sun.
    The Earth does not revolve around the Sun.
    Water is essential for life.
    Humans always drink clean water.
    """

    manager = DebateManager()
    report = manager.run(text)

    print("\n--- FINAL CONSISTENCY REPORT ---")
    for key, value in report.items():
        print(f"{key}: {value}")


        # utils.py

import re

def clean_text(text):
    """
    Cleans input text by removing extra spaces and newlines.
    """
    text = text.replace("\n", " ")
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def split_sentences(text):
    """
    Splits text into sentences using punctuation.
    """
    sentences = re.split(r'[.!?]', text)
    return [s.strip() for s in sentences if len(s.strip()) > 0]


def contains_absolute_words(sentence):
    """
    Checks for absolute words which often indicate weak claims.
    """
    absolute_words = ["always", "never", "all", "none", "completely"]
    return any(word in sentence.lower() for word in absolute_words)


def keyword_overlap(sent1, sent2):
    """
    Calculates simple keyword overlap between two sentences.
    """
    words1 = set(sent1.lower().split())
    words2 = set(sent2.lower().split())
    if not words1 or not words2:
        return 0
    return len(words1.intersection(words2))


def calculate_consistency_score(num_claims, num_contradictions):
    """
    Calculates consistency score out of 100.
    """
    if num_claims == 0:
        return 100
    penalty = num_contradictions * 20
    score = max(0, 100 - penalty)
    return score

    
from utils import clean_text, split_sentences
from utils import contains_absolute_words
from utils import calculate_consistency_score


context = input_text
claim = hypothesis

context = novel_text          # Full novel
claim = hypothetical_backstory # Hypothetical backstory about a character


def chunk_text(text, chunk_size=1200, overlap=200):
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start = end - overlap
    return chunks



    def debate_pipeline(novel_text, backstory):
    chunks = chunk_text(novel_text)

    pro_arguments = []
    con_arguments = []

    for chunk in chunks:
        pro_arguments.append(pro_agent(chunk, backstory))
        con_arguments.append(con_agent(chunk, backstory))

    final_decision, explanation = judge_agent(
        pro_arguments,
        con_arguments
    )

    return final_decision, explanation




    import csv

def write_results(predictions, filename="results.csv"):
    with open(filename, mode="w", newline="") as file:
        writer = csv.writer(file)
        writer.writerow(["id", "prediction"])
        for idx, pred in enumerate(predictions):
            writer.writerow([idx, pred])



            from debate_pipeline import debate_pipeline
from submission_writer import write_results

def main(dataset):
    predictions = []

    for sample in dataset:
        novel_text = sample["novel"]
        backstory = sample["backstory"]

        label, _ = debate_pipeline(novel_text, backstory)
        predictions.append(label)

    write_results(predictions)

if __name__ == "__main__":
    dataset = load_dataset("test.json")  # Provided by hackathon
    main(dataset)